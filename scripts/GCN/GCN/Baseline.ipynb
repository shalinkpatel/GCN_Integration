{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import hypertunity as ht\n",
    "from sklearn import preprocessing\n",
    "\n",
    "with open('/gpfs_home/spate116/data/spate116/GCN/E116/data/data_embedding.pickle', 'rb') as f:\n",
    "    data_embedding = pickle.load(f)\n",
    "    \n",
    "with open('/gpfs_home/spate116/data/spate116/GCN/E116/data/data_class1.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "X = data_embedding\n",
    "y = torch.tensor(list(map(lambda x: x[0], data.y)), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(94, 1000),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(1000, 500),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(500, 100),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(100, 50),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(50, 2),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "device = torch.device('cuda')\n",
    "def train_model(net, X, y, epochs, learning_rate, train_mask, test_mask):\n",
    "    model = net.to(device)\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "    samples = len(X)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "    losses_train = []\n",
    "    losses_test = []\n",
    "    best_auc = -1\n",
    "    correct_pred = [y[i].item() for i in test_mask]\n",
    "    \n",
    "    weight_one = sum(y.cpu().numpy().tolist())/samples\n",
    "    weight = torch.tensor([weight_one, 1-weight_one]).to(device)\n",
    "    \n",
    "    pbar = tqdm(range(epochs))\n",
    "    for epoch in pbar:\n",
    "        model.train()\n",
    "        logits = model(X.float())\n",
    "\n",
    "        loss = F.cross_entropy(logits[train_mask], y[train_mask], weight=weight)\n",
    "        loss_test = F.cross_entropy(logits[test_mask], y[test_mask], weight=weight)\n",
    "        losses_train.append(loss.item())\n",
    "        losses_test.append(loss_test.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        pred = list(map(lambda x: np.argmax(x, axis = 0), torch.exp(F.log_softmax(logits, 1)).cpu().detach().numpy()))\n",
    "        auc = roc_auc_score(correct_pred, [pred[i] for i in test_mask], average='weighted')\n",
    "        best_auc = best_auc if best_auc > auc else auc\n",
    "\n",
    "        pbar.set_description('Best Test AUC: %.4f | Train Loss: %.4f | Test Loss: %.4f' % (best_auc, loss.item(), loss_test.item()))\n",
    "            \n",
    "    return losses_train, losses_test, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(30)\n",
    "idx = list(range(len(y)))\n",
    "random.shuffle(idx)\n",
    "train_mask = idx[:10000]\n",
    "test_mask = idx[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best Test AUC: 0.8608 | Train Loss: 0.4155 | Test Loss: 0.4539: 100%|██████████| 250/250 [00:09<00:00, 26.30it/s]\n"
     ]
    }
   ],
   "source": [
    "def weight_reset(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()\n",
    "\n",
    "model.apply(weight_reset)\n",
    "\n",
    "losses_train, losses_test, model = train_model(model, X, y, 250, 0.0005, train_mask, test_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
