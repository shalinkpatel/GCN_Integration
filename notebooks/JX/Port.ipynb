{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ordered_set import OrderedSet\n",
    "from six.moves import cPickle as pickle \n",
    "from collections import defaultdict\n",
    "from scipy.sparse import load_npz\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch_geometric\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = load_npz('/gpfs/data/rsingh47/jbigness/data/E116/hic_sparse_vcsqrt_oe_edge_v7.npz')\n",
    "hms = np.load('/gpfs/data/rsingh47/jbigness/data/E116/np_hmods_norm_vcsqrt_oe_edge_v7.npy')\n",
    "labs = np.load('/gpfs/data/rsingh47/jbigness/data/E116/np_nodes_lab_genes_vcsqrt_oe_edge_v7.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.tensor(labs[:,-1]).long()\n",
    "extract = torch_geometric.utils.from_scipy_sparse_matrix(mat)\n",
    "G = torch_geometric.data.Data(edge_index = extract[0], \n",
    "                              edge_attr = extract[1], \n",
    "                              x = torch.tensor(hms[:mat.shape[0]]).float().reshape(-1, 1, 100, 5), \n",
    "                              y = torch.tensor(labs[:,-2]).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/gpfs_home/spate116/ml/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/gpfs_home/spate116/ml/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/gpfs_home/spate116/ml/lib/python3.7/site-packages/torch_geometric/data/cluster.py\", line 148, in __collate__\n    start = self.cluster_data.partptr[batch].tolist()\nRuntimeError: CUDA error: initialization error\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c90f2385ce8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                              num_workers=6)\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs_home/spate116/ml/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs_home/spate116/ml/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs_home/spate116/ml/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs_home/spate116/ml/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/gpfs_home/spate116/ml/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/gpfs_home/spate116/ml/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/gpfs_home/spate116/ml/lib/python3.7/site-packages/torch_geometric/data/cluster.py\", line 148, in __collate__\n    start = self.cluster_data.partptr[batch].tolist()\nRuntimeError: CUDA error: initialization error\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import ClusterData, ClusterLoader\n",
    "\n",
    "cluster_data = ClusterData(G, num_parts=10, recursive=False,\n",
    "                           save_dir='/gpfs_home/spate116/singhlab/GCN_Integration/notebooks/JX')\n",
    "train_loader = ClusterLoader(cluster_data, batch_size=2, shuffle=True,\n",
    "                             num_workers=6)\n",
    "\n",
    "for d in train_loader:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import SAGEConv, ChebConv, TAGConv, GATConv, ARMAConv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, hidden_size1, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = TAGConv(in_feats, hidden_size, K = 3)\n",
    "        self.conv2 = TAGConv(hidden_size, hidden_size1)\n",
    "        self.conv3 = TAGConv(hidden_size1, num_classes)\n",
    "        x = 10\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, x, (3, 3)),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout2d(),\n",
    "            nn.Conv2d(x, 2*x, (3, 2)),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout2d(),\n",
    "            nn.Conv2d(2*x, 1, (3, 2)),\n",
    "        )\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        h = self.encoder(inputs).reshape(-1, 94)\n",
    "        h = torch.tanh(h)\n",
    "        h = F.dropout(h, training=self.training)\n",
    "        h = self.conv1(h, g.edge_index)\n",
    "        h = torch.tanh(h)\n",
    "        h = F.dropout(h, training=self.training)\n",
    "        h = self.conv2(h, g.edge_index)\n",
    "        h = torch.tanh(h)\n",
    "        h = F.dropout(h, training=self.training)\n",
    "        h = self.conv3(h, g.edge_index)\n",
    "        h = F.softmax(h, dim=1)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "device = torch.device('cuda')\n",
    "def train_model(net, data_loader, epochs, learning_rate, train_mask, test_mask, mask):\n",
    "    model = net.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "    losses_train = []\n",
    "    losses_test = []\n",
    "    best_auc = -1\n",
    "\n",
    "    pbar = tqdm(range(epochs))\n",
    "    for epoch in pbar:\n",
    "        logits = []\n",
    "        y = []\n",
    "        for d in data_loader:\n",
    "            d = d.to(device)\n",
    "            model.train()\n",
    "            logits.append(model(d, d.x.float()))\n",
    "            y.append(d.y)\n",
    "        \n",
    "        logits = torch.cat(logits, dim=0)[mask]\n",
    "        y = torch.cat(y, dim = 0)\n",
    "        \n",
    "        loss = F.cross_entropy(logits[train_mask], y[train_mask])\n",
    "        loss_test = F.cross_entropy(logits[test_mask], y[test_mask])\n",
    "        losses_train.append(loss.item())\n",
    "        losses_test.append(loss_test.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        pred = list(map(lambda x: np.argmax(x, axis = 0), torch.exp(F.log_softmax(logits, 1)).cpu().detach().numpy()))\n",
    "        auc = roc_auc_score(y[test_mask], [pred[i] for i in test_mask], average='weighted')\n",
    "        best_auc = best_auc if best_auc > auc else auc\n",
    "\n",
    "        pbar.set_description('Best Test AUC: %.4f | Train Loss: %.4f | Test Loss: %.4f' % (best_auc, loss.item(), loss_test.item()))\n",
    "\n",
    "    return losses_train, losses_test, model, best_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(30)\n",
    "idx = list(range(G.y.shape[0]))\n",
    "random.shuffle(idx)\n",
    "train_mask = idx[:10000]\n",
    "test_mask = idx[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = GCN(94, 100, 50, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_train, losses_test, model, best_auc = train_model(net, train_loader, 4000, 0.01, train_mask, test_mask, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
