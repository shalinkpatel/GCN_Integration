{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ordered_set import OrderedSet\n",
    "from six.moves import cPickle as pickle \n",
    "from collections import defaultdict\n",
    "from scipy.sparse import load_npz\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch_geometric\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = load_npz('/gpfs/data/rsingh47/jbigness/data/E116/hic_sparse_vcsqrt_oe_edge_v7.npz')\n",
    "hms = np.load('/gpfs/data/rsingh47/jbigness/data/E116/np_hmods_norm_vcsqrt_oe_edge_v7.npy')\n",
    "labs = np.load('/gpfs/data/rsingh47/jbigness/data/E116/np_nodes_lab_genes_vcsqrt_oe_edge_v7.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.tensor(labs[:,-1]).long()\n",
    "loc = {}\n",
    "for i in range(labs[:, -1].shape[0]):\n",
    "    loc[labs[i, -1]] = i\n",
    "y = []\n",
    "for i in range(mat.shape[0]):\n",
    "    y.append(labs[loc[i],-2]) if i in mask else y.append(-1)\n",
    "y = torch.tensor(y).long()\n",
    "extract = torch_geometric.utils.from_scipy_sparse_matrix(mat)\n",
    "G = torch_geometric.data.Data(edge_index = extract[0], \n",
    "                              edge_attr = extract[1], \n",
    "                              x = torch.tensor(hms[:mat.shape[0]]).float().reshape(-1, 1, 100, 5), \n",
    "                              y = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing METIS partitioning...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import ClusterData, ClusterLoader\n",
    "\n",
    "cluster_data = ClusterData(G, num_parts=80, recursive=False,\n",
    "                           save_dir='/gpfs_home/spate116/singhlab/GCN_Integration/notebooks/JX')\n",
    "train_loader = ClusterLoader(cluster_data, batch_size=1, shuffle=False,\n",
    "                             num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import SAGEConv, ChebConv, TAGConv, GATConv, ARMAConv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, hidden_size1, hidden_size2, hidden_size3, num_classes, conv):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = conv(in_feats, hidden_size)\n",
    "        self.conv2 = conv(hidden_size, hidden_size1)\n",
    "        self.conv3 = conv(hidden_size1, hidden_size2)\n",
    "        self.conv4 = conv(hidden_size2, hidden_size3)\n",
    "        self.conv5 = conv(hidden_size3, num_classes)\n",
    "        x = 10\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, x, (3, 3)),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout2d(),\n",
    "            nn.Conv2d(x, 2*x, (3, 2)),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout2d(),\n",
    "            nn.Conv2d(2*x, 1, (3, 2)),\n",
    "        )\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        h = self.encoder(inputs).reshape(-1, 94)\n",
    "        h = torch.tanh(h)\n",
    "        h = F.dropout(h, training=self.training)\n",
    "        h = self.conv1(h, g.edge_index)\n",
    "        h = torch.tanh(h)\n",
    "        h = F.dropout(h, training=self.training)\n",
    "        h = self.conv2(h, g.edge_index)\n",
    "        h = torch.tanh(h)\n",
    "        h = F.dropout(h, training=self.training)\n",
    "        h = self.conv3(h, g.edge_index)\n",
    "        h = torch.tanh(h)\n",
    "        h = F.dropout(h, training=self.training)\n",
    "        h = self.conv4(h, g.edge_index)\n",
    "        h = torch.tanh(h)\n",
    "        h = F.dropout(h, training=self.training)\n",
    "        h = self.conv5(h, g.edge_index)\n",
    "        h = F.softmax(h, dim=1)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "device = torch.device('cuda')\n",
    "def train_model(net, data_loader, epochs, learning_rate, train_mask, test_mask, mask):\n",
    "    model = net.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "    losses_train = []\n",
    "    losses_test = []\n",
    "    best_auc = -1\n",
    "\n",
    "    pbar = tqdm(range(epochs))\n",
    "    for epoch in pbar:\n",
    "        logits = []\n",
    "        y = []\n",
    "        for d in data_loader:\n",
    "            d = d.to(device)\n",
    "            model.train()\n",
    "            logits.append(model(d, d.x.float()))\n",
    "            y.append(d.y)\n",
    "        \n",
    "        logits = torch.cat(logits, dim=0).to(device)\n",
    "        y = torch.cat(y, dim=0)\n",
    "        mask = (y != -1)\n",
    "        \n",
    "        logits = logits[mask]\n",
    "        y = y[mask]\n",
    "        \n",
    "        loss = F.cross_entropy(logits[train_mask], y[train_mask])\n",
    "        loss_test = F.cross_entropy(logits[test_mask], y[test_mask])\n",
    "        losses_train.append(loss.item())\n",
    "        losses_test.append(loss_test.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        pred = list(map(lambda x: np.argmax(x, axis = 0), torch.exp(F.log_softmax(logits, 1)).cpu().detach().numpy()))\n",
    "        auc = roc_auc_score(y[test_mask].cpu().numpy(), [pred[i] for i in test_mask], average='weighted')\n",
    "        best_auc = best_auc if best_auc > auc else auc\n",
    "\n",
    "        pbar.set_description('Best Test AUC: %.4f | Train Loss: %.4f | Test Loss: %.4f' % (best_auc, loss.item(), loss_test.item()))\n",
    "\n",
    "    return losses_train, losses_test, model, best_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(30)\n",
    "idx = list(range(labs.shape[0] - 1))\n",
    "random.shuffle(idx)\n",
    "train_mask = idx[:10000]\n",
    "test_mask = idx[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = GCN(94, 1000, 750, 400, 50, 2, ARMAConv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best Test AUC: 0.5018 | Train Loss: 0.7758 | Test Loss: 0.7774:   1%|          | 15/2000 [01:16<2:47:53,  5.07s/it]\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/gpfs_home/spate116/ml/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-9-fa600bc70e87>\", line 1, in <module>\n",
      "    losses_train, losses_test, model, best_auc = train_model(net, train_loader, 2000, 0.0005, train_mask, test_mask, mask)\n",
      "  File \"<ipython-input-6-3257719153ec>\", line 20, in train_model\n",
      "    logits.append(model(d, d.x.float()))\n",
      "  File \"/gpfs_home/spate116/ml/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-5-f657c2831b81>\", line 34, in forward\n",
      "    h = self.conv3(h, g.edge_index)\n",
      "  File \"/gpfs_home/spate116/ml/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/gpfs_home/spate116/ml/lib/python3.7/site-packages/torch_geometric/nn/conv/arma_conv.py\", line 104, in forward\n",
      "    out = out @ self.init_weight\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/gpfs_home/spate116/ml/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/gpfs_home/spate116/ml/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/gpfs_home/spate116/ml/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/gpfs_home/spate116/ml/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/gpfs/runtime/opt/python/3.7.4/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/gpfs/runtime/opt/python/3.7.4/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/gpfs/runtime/opt/python/3.7.4/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/gpfs/runtime/opt/python/3.7.4/lib/python3.7/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/gpfs/runtime/opt/python/3.7.4/lib/python3.7/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/gpfs/runtime/opt/python/3.7.4/lib/python3.7/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/gpfs_home/spate116/ml/lib/python3.7/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "losses_train, losses_test, model, best_auc = train_model(net, train_loader, 2000, 0.0005, train_mask, test_mask, mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
